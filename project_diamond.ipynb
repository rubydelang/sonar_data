{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ee5e30-3aa9-4b48-a0d5-17cfabda8090",
   "metadata": {},
   "source": [
    "# Group Project: Determining Diamond Cut Grades Using KNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885149a0-49d2-4f86-bc62-8d8d75bda3ca",
   "metadata": {},
   "source": [
    "**Section 009 Group 2**\n",
    "\n",
    "**Ziqing Wang**<br>**Anna Tao**<br>**Ruby de Lang**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b84c2-52ec-477b-86f1-175048a2a1d9",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff5daf-4590-4153-a234-3e90ee3a8d64",
   "metadata": {},
   "source": [
    "The 4Cs: cut, clarity, color, and carat weight, are internationally accepted standards for assessing the quality of a diamond.  Diamond cut grade is a pivotal factor in determining the beauty and value of a diamond.\n",
    "\n",
    "The dataset being used reports on the characteristics of diamonds. \n",
    "We want to use the KNN classification method to predict the cut grades of diamonds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34104bd9-a16f-40df-959a-8d8c9760cfb3",
   "metadata": {},
   "source": [
    "The columns of the dataset:\n",
    "* **carat**: a unit of measurement for a diamond's weight.\n",
    "* **cut**: cut grades of diamonds, measured in five scales (high to low): Ideal, Premium, Very good, Good, Fair.\n",
    "* **color**: color is graded on a scale from D (colorless) to Z (light yellow or brown).\n",
    "* **clarity**: the presence of internal and external flaws within a diamond.\n",
    "* **depth**: the distance from the table to the culet (the bottom of the diamond).\n",
    "* **table**: the flat, topmost facet of diamonds.\n",
    "* **price**: The price of diamonds.\n",
    "* **x**: the x-dimension of diamonds.\n",
    "* **y**: the y-dimension of diamonds.\n",
    "* **z**: the z-dimension of diamonds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a97793-e74c-41b0-8f81-55d442ceff6b",
   "metadata": {},
   "source": [
    "### Method Overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d332e5-1ee0-4d01-9be6-9b8825480791",
   "metadata": {},
   "source": [
    "Our project wishes to identify whether we can use diamond data to predict the cut of a diamond.\n",
    "\n",
    "1. Preliminary Exploratory Data Analysis: Prepare our dataset by reading and wrangling for further analysis.\n",
    "2. Splitting Data: Split the filtered dataset into a testing and training set. Summarize the distribution of each categorical predictor variables for the training data.\n",
    "3. Select Predictor Variables: Check for the relationship between each variable and the cut quality. Eliminate the variables with no visible correlation.\n",
    "4. Create a Classification Model: Employ the K-nearest neighbors classification algorithm to identify the optimal K value. After identifying the most suitable value, run the model on the test set to check the accuracy value. \n",
    "5. Fulfill Curiousity by checking whether the addition of predictor variables increases or decreases the accuracy of predictions. We will do this by adding predictor variables to our recipe, then running that model on the test set to check the accuracy value. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3f84c-1e0c-4d52-85b6-78f14a56f807",
   "metadata": {},
   "source": [
    "### 1. Preliminary exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966a1768-8b35-4a7f-b9b8-569b52172248",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tidyverse\")\n",
    "install.packages(\"cowplot\")\n",
    "install.packages(\"tidymodels\")\n",
    "install.packages(\"kknn\")\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(readr)\n",
    "library(cowplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38990570-2b1f-4d7e-b440-7ed13fb5f914",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Reading Data from Online Source Into R**\n",
    "\n",
    "After reading the data from an online source into a CSV file in Jupyter, we have 53940 recorded observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75586178-ca29-43fa-943b-469c33e01c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in date_names_lang(date_names):\n",
      "“restarting interrupted promise evaluation”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in date_names_lang(date_names): read failed on /opt/conda/lib/R/library/readr/R/sysdata.rdb\n",
     "output_type": "error",
     "traceback": [
      "Error in date_names_lang(date_names): read failed on /opt/conda/lib/R/library/readr/R/sysdata.rdb\nTraceback:\n",
      "1. read_csv(\"https://raw.githubusercontent.com/rubydelang/sonar_data/main/diamonds.csv\")",
      "2. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
      "3. is_ascii_compatible(locale$encoding)",
      "4. iconv(list(charToRaw(\"\\n\")), from = \"ASCII\", to = encoding, toRaw = TRUE)",
      "5. default_locale()",
      "6. locale()",
      "7. date_names_lang(date_names)"
     ]
    }
   ],
   "source": [
    "diamond_data <- read_csv(\"https://raw.githubusercontent.com/rubydelang/sonar_data/main/diamonds.csv\") \n",
    "\n",
    "head(diamond_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e2160-ede9-48d0-9953-449daec2ee12",
   "metadata": {},
   "source": [
    "**Mutating Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07441242-8eb3-4c8d-ba9d-172bc8dbc6df",
   "metadata": {},
   "source": [
    "For our target variable ( column cut ), we need to mutate the type into a factor. This will allow us to predict the the cut quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac61b28-5d6d-4c05-ae47-8f92c8b6eeed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamond_data <- diamond_data |>\n",
    "mutate(cut = as_factor(cut))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f967156-7c51-48a1-86f2-b480c7f2faf4",
   "metadata": {},
   "source": [
    "**Checking for Missing Data** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b52038-5c84-4ab4-a1e1-ac7103fe73c0",
   "metadata": {},
   "source": [
    "The 'na_rows' counts for the number of rows containing missing data, and the result of 0 means we do not have any missing data in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d967537-10d9-4786-8d5e-cbf8c2951eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "na_rows <- sum(apply(is.na(diamond_data), 1, any))\n",
    "print(na_rows)\n",
    "summary(diamond_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd747e01-8e54-4028-a21e-6e0d3eec4579",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Tidy Data**\n",
    "\n",
    "Now looking at the dataset, each row is a single observation, each column is a single variable, with meaningful column names, and each cell contains only a single value. \n",
    "Therefore, the data is already tidy so we do not need take any further actions. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3979e47-c311-40e7-bff6-c71c3c24eb64",
   "metadata": {},
   "source": [
    "### 2. Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a9468-90b3-4c42-807a-7a46ecac9ace",
   "metadata": {},
   "source": [
    "**Splitting the data into training and testing data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38de021d-a89f-4fa3-8dc8-830512430646",
   "metadata": {},
   "source": [
    "We have 53940 recorded observations that can be used for analysis. Our next step is the split the data into a training and testing set. We set the proportion to 0.75, this means 75% of our 53940 observations will be used towards the training set, and the remaining observations will be stored for the testing set. We set our seed to 2023 to create replicable randomized results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd17ba-adda-44d3-9b45-21562f7486d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "diamond_split <- initial_split(diamond_data, prop = 0.75, strata = cut)\n",
    "diamond_training <- training(diamond_split)\n",
    "diamond_testing <- testing(diamond_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bfd36-bae9-445d-ad65-66e52a038bc6",
   "metadata": {},
   "source": [
    "**Examining the Distribution of Training data**\n",
    "\n",
    "In the following visualization, we examine the distribution of our target variable 'cut' in the training data set. **THIS SHOULD BE AN EVEN DISTRIBUTION OR DELETE THIS LATER!!!!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268a67f-c500-42da-bbd0-420ab2dd24ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counting_types <- diamond_training |>\n",
    "    group_by(cut)|>\n",
    "    summarize(types_count = n()) \n",
    "\n",
    "dist <- counting_types |>\n",
    "    ggplot(aes(x = cut, y = types_count, fill = cut)) +\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    labs(x = \"Cut QUality\",y = \"Patient Count\", color = \"Cut Quality\") +\n",
    "    ggtitle(\"Cut Quality Distribution\") +\n",
    "    scale_fill_discrete(name = \"Cut Quality\", labels = c(\"1\", \"2\", \"4\", \"5\")) +\n",
    "    theme(text = element_text(size = 20))\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894dc702-b915-4255-b8a5-30aab8f35216",
   "metadata": {},
   "source": [
    "**Predictor Distribution**\n",
    "\n",
    "Below are predictor variables for cut quality. We can observe their distribution and select those that exhibit some type of relationship with the target variable (cut quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69301b2-cf62-4b04-aeda-fe7230a64230",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 13, repr.plot.height = 14)\n",
    "x_cut_graph <- diamond_training |>\n",
    "ggplot(aes(x = cut, y = x, color = cut)) +\n",
    "geom_boxplot() +\n",
    "ggtitle(\"Cut Grades vs x-dimension\") +\n",
    "labs(x =\"cut grades\", y = \"x-dimension of diamonds\", color = \"cut grades\")\n",
    "\n",
    "y_cut_graph <- diamond_training |>\n",
    "ggplot(aes(x = cut, y = y, color = cut)) +\n",
    "geom_boxplot() +\n",
    "ggtitle(\"Cut Grades vs y-dimension\") +\n",
    "labs(x =\"cut grades\", y = \"y-dimension of diamonds\", color = \"cut grades\")\n",
    "\n",
    "z_cut_graph <- diamond_training |>\n",
    "ggplot(aes(x = cut, y = z, color = cut)) +\n",
    "geom_boxplot() +\n",
    "ggtitle(\"Cut Grades vs z-dimension\") +\n",
    "labs(x =\"cut grades\", y = \"z-dimension of diamonds\", color = \"cut grades\")\n",
    "\n",
    "table_cut_graph <- diamond_training |>\n",
    "ggplot(aes(x = cut, y = table, color = cut)) +\n",
    "geom_boxplot() +\n",
    "ggtitle(\"Cut Grades vs Table\") +\n",
    "labs(x =\"cut grades\", y = \"table of diamonds\", color = \"cut grades\")\n",
    "\n",
    "depth_cut_graph <- diamond_training |>\n",
    "ggplot(aes(x = cut, y = depth, color = cut)) +\n",
    "geom_boxplot() +\n",
    "ggtitle(\"Cut Grades vs Depth\") +\n",
    "labs(x =\"cut grades\", y = \"depth of diamonds\", color = \"cut grades\")\n",
    "\n",
    "carat_cut_graph <- diamond_training |>\n",
    "ggplot(aes(x = cut, y = carat, color = cut)) +\n",
    "geom_boxplot() +\n",
    "ggtitle(\"Cut Grades vs Carat\") +\n",
    "labs(x =\"cut grades\", y = \"carat of diamonds\", color = \"cut grades\")\n",
    "\n",
    "price_cut_graph <- diamond_training |>\n",
    "ggplot(aes(x = cut, y = price, color = cut)) +\n",
    "geom_boxplot() +\n",
    "ggtitle(\"Cut Grades vs price\") +\n",
    "labs(x =\"cut grades\", y = \"price of diamonds\", color = \"cut grades\")\n",
    "\n",
    "plot_grid(x_cut_graph, y_cut_graph, z_cut_graph, table_cut_graph, depth_cut_graph, carat_cut_graph, price_cut_graph, align = \"h\", ncol = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1aa8e3-9ea4-499b-a708-a3e5e0e124a5",
   "metadata": {},
   "source": [
    "The more separate the boxes are, the more accurate prediction it will make. Based on the graph, none of them have strong relationships with the cut grades. We can maximize the prediction accuracy by choosing the relatively associated factors like: depth and table. These two variables show a slight change in the cut quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b3842-9c5c-4b10-b9a8-d9596ca6ffc0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20d43283-b2c0-4100-b6dc-dcc1fd518561",
   "metadata": {},
   "source": [
    "\n",
    "In reality, the cut grades are classified based on how well the diamond can reflect light. x, y, z, depth, and table are symmetry factors and should be considered as predictors. However, based on the graphs we have plotted, the associations are weak. Therefore, we should only choose depth and table as predictors. If the accuracy is not desirable, we will add the x, y, and z in, and compare the accuracy. We will visualize the results by plotting the accuracy graphs. We hypothesize the addition of x, y, and z columns will not affect the accuracy too much because the boxes of each type looks almost identical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107a8ce-b505-4887-a2bb-0103bd807713",
   "metadata": {},
   "source": [
    "### Building a Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d890f0a-35f7-4e89-aa48-70e5c649bc55",
   "metadata": {},
   "source": [
    "First, let's choose a reasonable k value to work with. We use tuning to select the best k value, and use cross validation to make sure the accuracy is not an unlucky value. **Warning: This step needs approximately 20 minutes to perform.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a20e3-96ca-4038-8fbf-6f49cc340388",
   "metadata": {},
   "source": [
    "**Creating a recipe**\n",
    "\n",
    "Our first step in building the classification model is to create a recipe so our training data can be prepared to be used in the model. We included both the scale and center functions to ensure all our predictor variables have a mean of zero and standard deviation of one to ensure a bell curve distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0e2ad-c35f-4d2c-b71e-eeeb15f9f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "diamond_recipe <- recipe(cut ~ depth+table, data = diamond_training) |>\n",
    "step_scale(all_predictors()) |>\n",
    "step_center(all_predictors())\n",
    "\n",
    "diamond_recipe_scaled <- diamond_recipe |>\n",
    "                       prep() |>\n",
    "                       bake(diamond_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606300b-e359-4085-9e50-ccd51f7e251c",
   "metadata": {},
   "source": [
    "**Creating a tuning model**\n",
    "\n",
    "After scaling the training data, our next step is to identify the best K value. To begin the tuning process, we'll define a model specification for classification. The tune() function will then manage the tuning of all predictors within the model to select the optimal k-value for enhanced model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8182c1e-730b-4c50-aa16-e149eefc0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83fd36-56c8-4acc-b589-6b65542a86ea",
   "metadata": {},
   "source": [
    "**Performing 5-fold cross validation**\n",
    "\n",
    "\n",
    "Following the model tuning, we performed a 5-fold cross-validation to obtain four distinct accuracy estimates for our final outcome. Opting for five folds was based on the medium size of our data, making it best to split it into five chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228abc1-2ae5-418c-a629-ce6d67c3fdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_vfold_5 <- vfold_cv(diamond_training, v = 5, strata = cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be9ba87-13fe-4fd3-b1c6-3b8d20755f43",
   "metadata": {},
   "source": [
    "**Collecting metrics for many values of K**\n",
    "\n",
    "First we create a tibbke using the seq() function starting from 1, incrementing by 10, and stopping at 151 (our dataset is on the larger side, so more K values are necessary). This allows us the tune the parameters of the KNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a9a121-5949-40e6-ba08-1ecc2f3e4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 151, by = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e6d302-5d62-4d31-9c55-72d42f8cd4f7",
   "metadata": {},
   "source": [
    "**Workflow**\n",
    "\n",
    "We then created a workflow for our model that includes the initial recipe (diamond_recipe), tuned spec (diamond_spec), and the tune_grid() function (this fits the model and all observations into a range specified from our tibble created earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f875a17-bac4-4749-9dce-61cd2daba698",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_fit_tune_1 <- workflow() |>\n",
    "  add_recipe(diamond_recipe) |>\n",
    "  add_model(diamond_spec) |>\n",
    "  tune_grid(resamples = diamond_vfold_5, grid = k_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2088a54-398d-4ae1-8501-f13942904331",
   "metadata": {},
   "source": [
    "**Collecting and Filtering the Accuracy**\n",
    "\n",
    "We use the collect_metrics() function and filter() function to collect the mean and standard error values of all five accuracy values. This will leave us with only the filtered metrics of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d678736-ab84-4d5e-bdfb-e6cf30587385",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond_vfold_tune_metrics_1 <- diamond_fit_tune_1 |>\n",
    "    collect_metrics() |> \n",
    "    filter(.metric == \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b0887-df62-4c95-b630-17d55fec723e",
   "metadata": {},
   "source": [
    "All of these steps can be found below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef10bb8-6e76-4368-839a-792dd90605c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "diamond_recipe <- recipe(cut ~ depth+table, data = diamond_training) |>\n",
    "step_scale(all_predictors()) |>\n",
    "step_center(all_predictors())\n",
    "\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 151, by = 10))\n",
    "diamond_vfold_5 <- vfold_cv(diamond_training, v = 5, strata = cut)\n",
    "\n",
    "diamond_fit_tune_1 <- workflow() |>\n",
    "  add_recipe(diamond_recipe) |>\n",
    "  add_model(diamond_spec) |>\n",
    "  tune_grid(resamples = diamond_vfold_5, grid = k_vals)\n",
    "\n",
    "diamond_vfold_tune_metrics_1 <- diamond_fit_tune_1 |>\n",
    "collect_metrics() |> filter(.metric == \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebab39-7c38-473d-b843-a9a63d3218bf",
   "metadata": {},
   "source": [
    "**Accuracy vs k graph**\n",
    "\n",
    "After filtering for the accuracy values, a visualization graph with the accuracies  vs neighbors is created to see which neighbour is the most stable. We estimate the nearest neighbor by looking at which one has the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267846d6-1968-485d-a015-d0ac53c0575d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 7, repr.plot.height = 6)\n",
    "\n",
    "accuracy_plot <- ggplot(diamond_vfold_tune_metrics_1, aes(x = neighbors, y = mean)) +\n",
    "geom_point() +\n",
    "geom_line() +\n",
    "ggtitle(\"Accuracy vs. K\")+\n",
    "labs(x = \"# of k\", y = \"accuracy in %\")\n",
    "\n",
    "accuracy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a36753-7b08-4cae-9aa5-0d7e9fd9981c",
   "metadata": {},
   "source": [
    "The graph above suggests that the selection of k between 50-150 would be the best choice for K, so let's pick a relatively smaller number to speed up our remaining calculations. 70 looks to be a good k value to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d245f8f-7b03-4f4d-a87c-f7da670a7da1",
   "metadata": {},
   "source": [
    "**Selecting the k with greatest accuracy**\n",
    "\n",
    "To confirm the conclusion we reached above, we will filter for the highest average max accuracy value and then select the k that corresponds to the max accuracy found. Then we can pull it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c50477-e5f9-48f1-99e7-f13b6e441dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k_v <- diamond_vfold_tune_metrics_1 |>\n",
    "          filter(mean == max(mean)) |>        \n",
    "          select(neighbors)\n",
    "best_k_v\n",
    "\n",
    "best_k_vV <- best_k_v |>\n",
    "pull()\n",
    "\n",
    "best_k_vV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7986e87-6226-4875-b71b-54f024f6de39",
   "metadata": {},
   "source": [
    "**Creating the optimized model with new K value**\n",
    "\n",
    "Now that we have identified the best k value (70), our next step is to run the same model using the best k value, but this time on our testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd989b66-6852-4c11-a4a0-262aaf729d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_spec_final <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 70) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "diamond_fit_final <- workflow() |>\n",
    "  add_recipe(diamond_recipe) |>\n",
    "  add_model(diamond_spec_final) |>\n",
    "  fit(diamond_training)\n",
    "\n",
    "diamond_predict <- predict(diamond_fit_final, diamond_testing) |>bind_cols(diamond_testing)\n",
    "\n",
    "diamond_prediction_accuracy <- diamond_predict |>\n",
    "  metrics(truth = cut, estimate = .pred_class) |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "diamond_prediction_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0265c-5f5c-407d-aee1-a5b90b3a9210",
   "metadata": {},
   "source": [
    "**Fitting the model**\n",
    "\n",
    "Then we can fit the model according to the training model, initial recipe, and tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f36480-3a95-4662-8ecc-7f4d15013a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_fit_final <- workflow() |>\n",
    "  add_recipe(diamond_recipe) |>\n",
    "  add_model(diamond_spec_final) |>\n",
    "  fit(diamond_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6715813-c04c-4d7c-86b0-84f67212870f",
   "metadata": {},
   "source": [
    "**Determing classification model's accuracy using the test set**\n",
    "\n",
    "The classification model is run now using the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773eb858-b65b-422c-9127-b2cbd48183de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_predict <- predict(diamond_fit_final, diamond_testing) |>bind_cols(diamond_testing)\n",
    "\n",
    "diamond_prediction_accuracy <- diamond_predict |>\n",
    "  metrics(truth = cut, estimate = .pred_class) |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "diamond_prediction_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c58421-333f-4abf-90a2-eb4f4dfa8c7b",
   "metadata": {},
   "source": [
    "We can see the final accuracy is 70.8%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea004dd-42d7-49f7-ae25-019dc579a03a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fulfilling Curiousity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295867b-193e-4082-bb9b-cf232b8f4d8d",
   "metadata": {},
   "source": [
    "**Fufilling Curiousity**\n",
    "\n",
    "Now we want to fulfill our curiosity. Will adding x,y,z as the predictors affect the accuracy, even the relationship graph from section 2 does not show strong relationships. So we can do that by repeating the same steps we used before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132cd4c-54e5-477c-8092-0690dcc69c6f",
   "metadata": {},
   "source": [
    "**Creating the recipe**\n",
    "\n",
    "We will create a recipe here, this time adding x, y, and z as predictors. Other than that we follow the same steps as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd8ded6-5eca-4cda-857a-f963eecaf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_recipe_curiosity <- recipe(cut ~ depth+table+x+y+z, data = diamond_training) |>\n",
    "step_scale(all_predictors()) |>\n",
    "step_center(all_predictors())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e7ff5-0a7f-4eaa-9923-d4a2f49efda1",
   "metadata": {},
   "source": [
    "**Fitting the recipe to a workflow**\n",
    "\n",
    "Now we fit it to the workflow, this time adding our new recipe (diamond_fit_tune_curiosity), other than that, all our steps remain the same. We use the same model diamond_spec.\n",
    "\n",
    "We then collect and filter the accuracy metrics to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f73803-5742-4434-9440-58c3c30597ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond_fit_tune_curiosity <- workflow() |>\n",
    "  add_recipe(diamond_recipe_curiosity) |>\n",
    "  add_model(diamond_spec) |>\n",
    "  tune_grid(resamples = diamond_vfold_5, grid = k_vals)\n",
    "\n",
    "diamond_vfold_tune_metrics_curiosity <- diamond_fit_tune_curiosity |>\n",
    "    collect_metrics() |> \n",
    "    filter(.metric == \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd900e3-df9a-4735-8b3e-c1fa65cbc398",
   "metadata": {},
   "source": [
    "**Plotting the curiousity accuracy graph**\n",
    "\n",
    "Here, we plot the new plot to find the best k-value. Similar to our last graph, we estimate the Nearest-Neighbour to be the one with the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b211a0-fdd5-4c90-888f-9f164125980e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_curiosity_plot <- ggplot(diamond_vfold_tune_metrics_curiosity, aes(x = neighbors, y = mean)) +\n",
    "geom_point() +\n",
    "geom_line() +\n",
    "labs(x = \"# of k\", y = \"accuracy in %\") +\n",
    "ggitle(\"Accuracy vs K\")+\n",
    "scale_x_continuous(breaks = seq(from = 0, to = 150, by = 10))\n",
    "\n",
    "accuracy_curiosity_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9449fe0-1477-4bef-b0b8-41600a029500",
   "metadata": {},
   "source": [
    "The graph above suggests the k value to be 10. Now let's test on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16caf7cc-ca34-4f27-b0c6-862878e401b9",
   "metadata": {},
   "source": [
    "**Curiousity Recipe**\n",
    "\n",
    "We create our tuning model using the best k value (10). Then we run the same model using neighbours = 10 on our test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d123b-b016-4fe1-bea9-d5504e975b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_spec_curiosity <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 10) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804a109-af0a-4930-9d71-3ebcb0d9303c",
   "metadata": {},
   "source": [
    "**Fitting the model**\n",
    "\n",
    "Similar to when the training data was used for the classification model, we created a workflow for our model that includes our newly cretaes recipe (diamond_recipe_curiousity), recently tuned model (diamond_spec_curiosity), and the fit() function to build the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934eab1e-e5fb-43ae-9c28-2a13961a5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2023)\n",
    "\n",
    "diamond_fit_curiosity <- workflow() |>\n",
    "  add_recipe(diamond_recipe_curiosity) |>\n",
    "  add_model(diamond_spec_curiosity) |>\n",
    "  fit(diamond_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03944817-b2f5-4ba6-abeb-c61be463339f",
   "metadata": {},
   "source": [
    "**Determining the curiousity model's accuracy using the test set**\n",
    "\n",
    "We then run the testing dataset. It gives us approximately 73% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ae046-8a90-4b30-b6ce-0b981f066711",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond_predict_curiosity <- predict(diamond_fit_curiosity, diamond_testing) |>bind_cols(diamond_testing)\n",
    "\n",
    "diamond_prediction_accuracy_curiosity <- diamond_predict_curiosity |>\n",
    "  metrics(truth = cut, estimate = .pred_class) |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "diamond_prediction_accuracy_curiosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb400f5-3896-4564-a50e-4708b7133381",
   "metadata": {},
   "source": [
    "**Comparing them side-by-side**\n",
    "\n",
    "Let's take a look at them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b14d0-832e-4aca-a9e8-e5f26fbbe9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diamond_prediction_accuracy\n",
    "diamond_prediction_accuracy_curiosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a03254b-e7fc-4a64-985e-4b319e7f2a92",
   "metadata": {},
   "source": [
    "With only depth and table as our predictors, the accuracy is 70.8%, and after adding the x, y, z as the predictors, the accuracy is increased by 2%. Just like we hypothesized, the addition of the x,y,z does not affect the accuracy too much, even though they are the geometry factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858af35-e17f-4d78-81fb-5442b2bbb757",
   "metadata": {},
   "source": [
    "### 4.0 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e754c5-4279-41eb-aeb1-b1f5900438f1",
   "metadata": {},
   "source": [
    "The expected outcome is that the cut grade prediction accuracy will be low, as the associations are not strong. In terms of impacts, if the accuracy is desirable, the model can speed up the process of grading the diamonds.\n",
    "\n",
    "**4.1 Summary of Results**\\\n",
    "Through this data analysis, it was found that the depth and table are the main two quantitative predictors that can be used to predict the quality of a diamond. When the model ran with those two being used as predictors, it was found that the accuracy of the prediction is 70.8%. The model was then tested again but this time, using depth, table, and the geometric factors as the predictors, the accuracy when the three new variables were taken into account was 72.7% (1.9% accuracy increase). The main takeaway from this finding is that while geometric factors affect the overall visual aesthetic of the diamond, they have a very small impact on the cut. \\\n",
    "**4.2 Relation to Expectations**\\\n",
    "This is in line to what was expected with the prediction models. As seen in the box plots created in section 2, the predictive capabilities did not appear to look very strong from the get go. \\\n",
    "**4.3 Future Impacts**\\\n",
    "This can have impacts on the future of the diamond industry as it was found through this that the geometric factors have very little impact on the quality of the cut. The implications of this are that the process of grading diamonds can be streamlined, and the overselling of diamonds based on the geometric variables can be prevented as it was shown through this classification model that they don't affect the quality of the cut. \n",
    "\n",
    "**4.4 Future questions** \n",
    "1. What factors do affect the cut of the diamond the most?\n",
    "2. How can we improve the prediction accuracy? \n",
    "3. What other factors not considered in our model influence the prediction of cut quality?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008bb40-36ff-4a2f-8e48-4335e96774b1",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae790a37-a554-47e8-919c-ed2693d159f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Why Is A Diamond’s Cut Important?. (n.d.). BRILLIANT EARTH. https://www.brilliantearth.com/en-ca/diamond/buying-guide/cut/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166a4a4-342e-439e-9ee1-d250d635b52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
